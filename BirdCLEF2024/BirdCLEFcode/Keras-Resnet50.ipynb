{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 70203,
     "databundleVersionId": 8068726,
     "sourceType": "competition"
    },
    {
     "sourceId": 8541535,
     "sourceType": "datasetVersion",
     "datasetId": 5102884
    },
    {
     "sourceId": 8561040,
     "sourceType": "datasetVersion",
     "datasetId": 5117090
    },
    {
     "sourceId": 8592075,
     "sourceType": "datasetVersion",
     "datasetId": 5139513
    },
    {
     "sourceId": 172963793,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 180231960,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 6106,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 4649
    },
    {
     "sourceId": 6125,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 4596
    },
    {
     "sourceId": 6127,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 4598
    }
   ],
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Import Module",
   "metadata": {
    "papermill": {
     "duration": 0.065343,
     "end_time": "2022-03-08T03:18:11.885586",
     "exception": false,
     "start_time": "2022-03-08T03:18:11.820243",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # \"jax\" or \"tensorflow\" or \"torch\" \n\nimport keras_cv\nimport keras\nimport keras.backend as K\nimport tensorflow as tf\nimport tensorflow_io as tfio\n\nimport numpy as np \nimport pandas as pd\n\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport librosa\nimport IPython.display as ipd\nimport librosa.display as lid\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\ncmap = mpl.cm.get_cmap('coolwarm')",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.632068,
     "end_time": "2022-03-08T03:18:14.585094",
     "exception": false,
     "start_time": "2022-03-08T03:18:11.953026",
     "status": "completed"
    },
    "tags": [],
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.232854Z",
     "iopub.execute_input": "2024-06-05T04:49:10.234016Z",
     "iopub.status.idle": "2024-06-05T04:49:10.241398Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.233978Z",
     "shell.execute_reply": "2024-06-05T04:49:10.240009Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_33/1585041062.py:23: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  cmap = mpl.cm.get_cmap('coolwarm')\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# CFG & Set seed",
   "metadata": {
    "papermill": {
     "duration": 0.066353,
     "end_time": "2022-03-08T03:18:18.099835",
     "exception": false,
     "start_time": "2022-03-08T03:18:18.033482",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "class CFG:\n    seed = 42\n    \n    # Input image size and batch size\n    img_size = [128, 384]\n    \n    # Audio duration, sample rate, and length\n    duration = 15 # second\n    sample_rate = 32000\n    audio_len = duration*sample_rate\n    \n    # STFT parameters\n    nfft = 2028\n    window = 2048\n    hop_length = audio_len // (img_size[1] - 1)\n    fmin = 20\n    fmax = 16000\n    \n    # Number of epochs, model name\n    preset = 'yolo_v8_s_backbone_coco'\n\n    # Class Labels for BirdCLEF 24\n    class_names = sorted(os.listdir('/kaggle/input/birdclef-2024/train_audio/'))\n    num_classes = len(class_names)\n    class_labels = list(range(num_classes))\n    label2name = dict(zip(class_labels, class_names))\n    name2label = {v:k for k,v in label2name.items()}",
   "metadata": {
    "papermill": {
     "duration": 0.156464,
     "end_time": "2022-03-08T03:18:18.322809",
     "exception": false,
     "start_time": "2022-03-08T03:18:18.166345",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.243500Z",
     "iopub.execute_input": "2024-06-05T04:49:10.243894Z",
     "iopub.status.idle": "2024-06-05T04:49:10.255161Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.243849Z",
     "shell.execute_reply": "2024-06-05T04:49:10.254011Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "tf.keras.utils.set_random_seed(CFG.seed)",
   "metadata": {
    "papermill": {
     "duration": 0.153451,
     "end_time": "2022-03-08T03:18:18.685056",
     "exception": false,
     "start_time": "2022-03-08T03:18:18.531605",
     "status": "completed"
    },
    "tags": [],
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.256574Z",
     "iopub.execute_input": "2024-06-05T04:49:10.257495Z",
     "iopub.status.idle": "2024-06-05T04:49:10.264671Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.257460Z",
     "shell.execute_reply": "2024-06-05T04:49:10.263434Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Dataset Path üìÅ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "BASE_PATH = '/kaggle/input/birdclef-2024'",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.266106Z",
     "iopub.execute_input": "2024-06-05T04:49:10.266430Z",
     "iopub.status.idle": "2024-06-05T04:49:10.276631Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.266402Z",
     "shell.execute_reply": "2024-06-05T04:49:10.275393Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Test Data üìñ",
   "metadata": {
    "papermill": {
     "duration": 0.067107,
     "end_time": "2022-03-08T03:18:26.962626",
     "exception": false,
     "start_time": "2022-03-08T03:18:26.895519",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "test_paths = glob(f'{BASE_PATH}/test_soundscapes/*ogg')\n# During commit use `unlabeled` data as there is no `test` data.\n# During submission `test` data will automatically be populated.\nif len(test_paths)==0:\n    test_paths = glob(f'{BASE_PATH}/unlabeled_soundscapes/*ogg')[:10]\ntest_df = pd.DataFrame(test_paths, columns=['filepath'])\ntest_df",
   "metadata": {
    "papermill": {
     "duration": 0.241649,
     "end_time": "2022-03-08T03:18:27.408813",
     "exception": false,
     "start_time": "2022-03-08T03:18:27.167164",
     "status": "completed"
    },
    "tags": [],
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.279081Z",
     "iopub.execute_input": "2024-06-05T04:49:10.279447Z",
     "iopub.status.idle": "2024-06-05T04:49:10.318474Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.279418Z",
     "shell.execute_reply": "2024-06-05T04:49:10.317361Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            filepath\n0  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n1  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n2  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n3  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n4  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n5  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n6  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n7  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n8  /kaggle/input/birdclef-2024/unlabeled_soundsca...\n9  /kaggle/input/birdclef-2024/unlabeled_soundsca...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>/kaggle/input/birdclef-2024/unlabeled_soundsca...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Modeling ü§ñ\n\nNote that our model was trained on `10 second` duration audio files, but we will infer on `5-second` audio files (as per competition rules). To facilitate this, we have set the model input shape to `(None, None, 3)`, which will allow us to have variable-length input during training and inference.",
   "metadata": {
    "papermill": {
     "duration": 0.182769,
     "end_time": "2022-03-08T03:20:04.861966",
     "exception": false,
     "start_time": "2022-03-08T03:20:04.679197",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import ResNet50\n\ndef identity_block(X, f, filters, stage, block):\n    conv_name_base = f'res{stage}{block}_branch'\n    bn_name_base = f'bn{stage}{block}_branch'\n\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n\n    X = Conv2D(F1, (1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(F2, (f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(F3, (1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\ndef convolutional_block(X, f, filters, stage, block, s=2):\n    conv_name_base = f'res{stage}{block}_branch'\n    bn_name_base = f'bn{stage}{block}_branch'\n\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n\n    X = Conv2D(F1, (1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(F2, (f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(F3, (1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X_shortcut = Conv2D(F3, (1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1')(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\ndef ResNet50(input_shape=(32, 32, 3)):\n    X_input = Input(input_shape)\n\n    X = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(X_input)\n    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    X = GlobalAveragePooling2D(name='avg_pool')(X)\n\n    X = Dense(2048, activation='relu')(X)\n    X = Dropout(0.5)(X)\n    X = Dense(10, activation='softmax', name='fc' + str(10))(X)\n\n    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n\n    return model\n\n# Example usage:\nmodel = ResNet50()\nmodel.summary()\n\n# Î™®Îç∏ Ïª¥ÌååÏùº\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Î™®Îç∏ ÏöîÏïΩ Ï∂úÎ†• (ÏÑ†ÌÉùÏÇ¨Ìï≠)\nmodel.summary()\n\n# Í∞ÄÏ§ëÏπò Î°úÎìú\nmodel.load_weights(\"/kaggle/input/soupmodel/birdclef-2024model5.h5\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.365063Z",
     "iopub.status.idle": "2024-06-05T04:49:10.365504Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.365311Z",
     "shell.execute_reply": "2024-06-05T04:49:10.365329Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def ResNet50(\n    include_top=True,\n    weights=\"imagenet\",\n    input_tensor=None,\n    input_shape=None,\n    pooling=None,\n    classes=1000,\n    classifier_activation=\"softmax\",\n):\n    \"\"\"Instantiates the ResNet50 architecture.\"\"\"\n\n    def stack_fn(x):\n        x = stack_residual_blocks_v1(x, 64, 3, stride1=1, name=\"conv2\")\n        x = stack_residual_blocks_v1(x, 128, 4, name=\"conv3\")\n        x = stack_residual_blocks_v1(x, 256, 6, name=\"conv4\")\n        return stack_residual_blocks_v1(x, 512, 3, name=\"conv5\")\n\n    return ResNet(\n        stack_fn,\n        False,\n        True,\n        \"resnet50\",\n        include_top,\n        weights,\n        input_tensor,\n        input_shape,\n        pooling,\n        classes,\n        classifier_activation=classifier_activation,\n    )\n\nimport tensorflow as tf\n\ndef get_model(shape=(None, None, 3), weights=\"imagenet\"):\n    model = ResNet50(input_shape=shape, include_top=False, weights=weights)\n    x = stack_residual_blocks_v1(input_shape, 64, 3, stride1=1, name=\"conv2\")\n    x = stack_residual_blocks_v1(x, 128, 4, name=\"conv3\")\n    x = stack_residual_blocks_v1(x, 256, 6, name=\"conv4\")\n    flatten = tf.keras.layers.GlobalAveragePooling2D()(x)\n    drop_out = tf.keras.layers.Dropout(0.5)(flatten)\n    dense = tf.keras.layers.Dense(2048, activation=\"relu\")(drop_out)\n    prediction = tf.keras.layers.Dense(182, activation=\"softmax\", name=\"prediction\")(dense)\n    model = tf.keras.Model(model.input, prediction)\n    return model\n\n# Î™®Îç∏ ÏÉùÏÑ±\nmodel = get_model()\n\n# Î™®Îç∏ Ïª¥ÌååÏùº\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Î™®Îç∏ ÏöîÏïΩ Ï∂úÎ†• (ÏÑ†ÌÉùÏÇ¨Ìï≠)\nmodel.summary()\n\n# Í∞ÄÏ§ëÏπò Î°úÎìú\nmodel.load_weights(\"birdclef-2024model5.h5\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.470177Z",
     "iopub.execute_input": "2024-06-05T04:49:10.470567Z",
     "iopub.status.idle": "2024-06-05T04:49:10.601905Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.470533Z",
     "shell.execute_reply": "2024-06-05T04:49:10.600145Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 47\u001B[0m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# Î™®Îç∏ ÏÉùÏÑ±\u001B[39;00m\n\u001B[0;32m---> 47\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# Î™®Îç∏ Ïª¥ÌååÏùº\u001B[39;00m\n\u001B[1;32m     50\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m),\n\u001B[1;32m     51\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     52\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[0;32mIn[15], line 35\u001B[0m, in \u001B[0;36mget_model\u001B[0;34m(shape, weights)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model\u001B[39m(shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m3\u001B[39m), weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 35\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mResNet50\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     x \u001B[38;5;241m=\u001B[39m stack_residual_blocks_v1(input_shape, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m3\u001B[39m, stride1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconv2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     37\u001B[0m     x \u001B[38;5;241m=\u001B[39m stack_residual_blocks_v1(x, \u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m4\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconv3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[15], line 18\u001B[0m, in \u001B[0;36mResNet50\u001B[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001B[0m\n\u001B[1;32m     15\u001B[0m     x \u001B[38;5;241m=\u001B[39m stack_residual_blocks_v1(x, \u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m6\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconv4\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m stack_residual_blocks_v1(x, \u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m3\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconv5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mResNet\u001B[49m(\n\u001B[1;32m     19\u001B[0m     stack_fn,\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresnet50\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     23\u001B[0m     include_top,\n\u001B[1;32m     24\u001B[0m     weights,\n\u001B[1;32m     25\u001B[0m     input_tensor,\n\u001B[1;32m     26\u001B[0m     input_shape,\n\u001B[1;32m     27\u001B[0m     pooling,\n\u001B[1;32m     28\u001B[0m     classes,\n\u001B[1;32m     29\u001B[0m     classifier_activation\u001B[38;5;241m=\u001B[39mclassifier_activation,\n\u001B[1;32m     30\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ResNet' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'ResNet' is not defined",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "import tensorflow as tf\n\ndef get_model(shape=(None, None, 3), weights=\"imagenet\"):\n    model = tf.keras.applications.ResNet50(input_shape=shape, include_top=False, weights=weights)\n    flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n    drop_out = tf.keras.layers.Dropout(0.5)(flatten)\n    dense = tf.keras.layers.Dense(2048, activation=\"relu\")(drop_out)\n    prediction = tf.keras.layers.Dense(182, activation=\"softmax\", name=\"prediction\")(dense)\n    model = tf.keras.Model(model.input, prediction)\n    return model\n\n# Î™®Îç∏ ÏÉùÏÑ±\nmodel = get_model()\n\n# Î™®Îç∏ Ïª¥ÌååÏùº\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Î™®Îç∏ ÏöîÏïΩ Ï∂úÎ†• (ÏÑ†ÌÉùÏÇ¨Ìï≠)\nmodel.summary()\n\n# Í∞ÄÏ§ëÏπò Î°úÎìú\nmodel.load_weights(\"birdclef-2024model5.h5\")\n",
   "metadata": {
    "papermill": {
     "duration": 1.239321,
     "end_time": "2022-03-08T03:20:06.281118",
     "exception": false,
     "start_time": "2022-03-08T03:20:05.041797",
     "status": "completed"
    },
    "tags": [],
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.602709Z",
     "iopub.status.idle": "2024-06-05T04:49:10.603142Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.602946Z",
     "shell.execute_reply": "2024-06-05T04:49:10.602963Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Data Loader üçö\n\nThe following code will decode the raw audio from `.ogg` file and also decode the spectrogram from the `audio` file. Additionally, we will apply Z-Score standardization and Min-Max normalization to ensure consistent inputs to the model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Decodes Audio\ndef build_decoder(with_labels=True, dim=1024):\n    def get_audio(filepath):\n        file_bytes = tf.io.read_file(filepath)\n        audio = tfio.audio.decode_vorbis(file_bytes) # decode .ogg file\n        audio = tf.cast(audio, tf.float32)\n        if tf.shape(audio)[1]>1: # stereo -> mono\n            audio = audio[...,0:1]\n        audio = tf.squeeze(audio, axis=-1)\n        return audio\n    \n    def create_frames(audio, duration=5, sr=32000):\n        frame_size = int(duration * sr)\n        audio = tf.pad(audio[..., None], [[0, tf.shape(audio)[0] % frame_size], [0, 0]]) # pad the end\n        audio = tf.squeeze(audio) # remove extra dimension added for padding\n        frames = tf.reshape(audio, [-1, frame_size]) # shape: [num_frames, frame_size]\n        return frames\n    \n    def apply_preproc(spec):\n        # Standardize\n        mean = tf.math.reduce_mean(spec)\n        std = tf.math.reduce_std(spec)\n        spec = tf.where(tf.math.equal(std, 0), spec - mean, (spec - mean) / std)\n\n        # Normalize using Min-Max\n        min_val = tf.math.reduce_min(spec)\n        max_val = tf.math.reduce_max(spec)\n        spec = tf.where(tf.math.equal(max_val - min_val, 0), spec - min_val,\n                              (spec - min_val) / (max_val - min_val))\n        return spec\n\n    def decode(path):\n        # Load audio file\n        audio = get_audio(path)\n        # Split audio file into frames with each having 5 seecond duration\n        audio = create_frames(audio)\n        # Convert audio to spectrogram\n        spec = keras.layers.MelSpectrogram(num_mel_bins=CFG.img_size[0],\n                                             fft_length=CFG.nfft, \n                                              sequence_stride=CFG.hop_length, \n                                              sampling_rate=CFG.sample_rate)(audio)\n        # Apply normalization and standardization\n        spec = apply_preproc(spec)\n        # Covnert spectrogram to 3 channel image (for imagenet)\n        spec = tf.tile(spec[..., None], [1, 1, 1, 3])\n        return spec\n    \n    return decode",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.604852Z",
     "iopub.status.idle": "2024-06-05T04:49:10.605390Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.605127Z",
     "shell.execute_reply": "2024-06-05T04:49:10.605150Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Build data loader\ndef build_dataset(paths, batch_size=1, decode_fn=None, cache=False):\n    if decode_fn is None:\n        decode_fn = build_decoder(dim=CFG.audio_len) # decoder\n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = (paths,)\n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls=AUTO) # decode audio to spectrograms then create frames\n    ds = ds.cache() if cache else ds # cache files\n    ds = ds.batch(batch_size, drop_remainder=False) # create batches\n    ds = ds.prefetch(AUTO)\n    return ds",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.607925Z",
     "iopub.status.idle": "2024-06-05T04:49:10.608846Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.608526Z",
     "shell.execute_reply": "2024-06-05T04:49:10.608558Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Inference üèÉ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize empty list to store ids\nids = []\n\n# Initialize empty array to store predictions\npreds = np.empty(shape=(0, CFG.num_classes), dtype='float32')\n\n# Build test dataset\ntest_paths = test_df.filepath.tolist()\ntest_ds = build_dataset(paths=test_paths, batch_size=1)\n\n# Iterate over each audio file in the test dataset\nfor idx, specs in enumerate(tqdm(iter(test_ds), desc='test ', total=len(test_df))):\n    # Extract the filename without the extension\n    filename = test_paths[idx].split('/')[-1].replace('.ogg','')\n    \n    # Convert to backend-specific tensor while excluding extra dimension\n    specs = keras.ops.convert_to_tensor(specs[0])\n    \n    # Predict bird species for all frames in a recording using all trained models\n    frame_preds = model.predict(specs, verbose=0)\n    \n    # Create a ID for each frame in a recording using the filename and frame number\n    frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(frame_preds))]\n    \n    # Concatenate the ids\n    ids += frame_ids\n    # Concatenate the predictions\n    preds = np.concatenate([preds, frame_preds], axis=0)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-05T04:53:21.069009Z",
     "iopub.execute_input": "2024-06-05T04:53:21.070153Z",
     "iopub.status.idle": "2024-06-05T04:53:21.125309Z",
     "shell.execute_reply.started": "2024-06-05T04:53:21.070114Z",
     "shell.execute_reply": "2024-06-05T04:53:21.123633Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Build test dataset\u001B[39;00m\n\u001B[1;32m      8\u001B[0m test_paths \u001B[38;5;241m=\u001B[39m test_df\u001B[38;5;241m.\u001B[39mfilepath\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m----> 9\u001B[0m test_ds \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_dataset\u001B[49m(paths\u001B[38;5;241m=\u001B[39mtest_paths, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Iterate over each audio file in the test dataset\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, specs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(\u001B[38;5;28miter\u001B[39m(test_ds), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest \u001B[39m\u001B[38;5;124m'\u001B[39m, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(test_df))):\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# Extract the filename without the extension\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'build_dataset' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'build_dataset' is not defined",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Submission ‚úâÔ∏è",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Submit prediction\npred_df = pd.DataFrame(ids, columns=['row_id'])\npred_df.loc[:, CFG.class_names] = preds\npred_df.to_csv('submission.csv',index=False)\npred_df.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-05T04:49:10.612560Z",
     "iopub.status.idle": "2024-06-05T04:49:10.612998Z",
     "shell.execute_reply.started": "2024-06-05T04:49:10.612765Z",
     "shell.execute_reply": "2024-06-05T04:49:10.612784Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
